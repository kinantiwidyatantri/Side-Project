<h2>Project Overview</h2>
<p>The project is structured into several key tasks to build, evaluate, and improve the image classifier:</p>

<h3>1. Building the Classifier</h3>
<p><strong>Objective:</strong> Create an image classifier using the kNN algorithm implemented from scratch.</p>
<p><strong>Approach:</strong></p>
<ul>
    <li>Implemented the kNN algorithm without relying on pre-built library functions.</li>
    <li>Used three different distance or similarity measures from libraries to compare images (excluding histogram-based measures).</li>
    <li>Ensured the classifier can switch between different measures based on input, using only one measure at a time.</li>
</ul>

<h3>2. Evaluating the Classifier</h3>
<p><strong>Objective:</strong> Assess the performance of the classifier using evaluation metrics.</p>
<p><strong>Approach:</strong></p>
<ul>
    <li>Developed a method to create a <em>confusion matrix</em>, visualizing the classifier's performance across different classes.</li>
    <li>Calculated key metrics: <strong>precision</strong>, <strong>recall</strong>, <strong>F-measure</strong>, and <strong>accuracy</strong>.</li>
    <li>Applied a macro-averaging approach to handle multiple classes and addressed edge cases to ensure accurate evaluation.</li>
</ul>

<h3>3. Improving with Cross-Validation</h3>
<p><strong>Objective:</strong> Enhance the classifier's reliability and generalization capability using cross-validation.</p>
<p><strong>Approach:</strong></p>
<ul>
    <li>Implemented the <em>k-fold cross-validation</em> technique, dividing the training data into k approximately equal-sized folds.</li>
    <li>Trained and tested the classifier across different folds to evaluate its performance on unseen data.</li>
    <li>Calculated average precision, recall, F-measure, and accuracy across all folds to obtain a comprehensive performance overview.</li>
</ul>

<h3>4. Optimizing the Number of Neighbors (k)</h3>
<p><strong>Objective:</strong> Determine the optimal number of neighbors (k) for the kNN algorithm to improve classification accuracy.</p>
<p><strong>Approach:</strong></p>
<ul>
    <li>Explored methods such as <em>cross-validation error analysis</em> to systematically select the best value of k.</li>
    <li>Investigated the impact of different k values on the classifier's performance.</li>
    <li>Considered approaches from reputable sources to guide the selection process (e.g., consult academic journals or machine learning textbooks).</li>
</ul>

<h3>5. Implementing Custom Similarity Measures</h3>
<p><strong>Objective:</strong> Enhance the classifier by implementing two similarity measures manually.</p>
<p><strong>Approach:</strong></p>
<ul>
    <li>Selected two of the three previously used similarity measures.</li>
    <li>Implemented these measures from scratch, avoiding reliance on advanced library functions (e.g., avoided using <code>numpy.linalg.norm</code>).</li>
    <li>Used basic operations and simple library functions for calculations like roots, powers, averages, or standard deviations.</li>
</ul>

<h2>Datasets Used</h2>
<p>The project utilizes excerpts from the following datasets:</p>
<ul>
    <li><a href="https://generated.photos">AI Generated Faces from Generated.Photos</a>: A collection of realistic human faces generated by artificial intelligence.</li>
    <li><a href="https://danikiyasseh.github.io/Turath/">Turath-150K Image Database of Arab Heritage</a>: A rich dataset containing images related to Arab heritage and culture.</li>
    <li><a href="https://dm.kaist.ac.kr/datasets/animal-10n/">ANIMAL-10N Dataset</a>: A dataset featuring images of animals, useful for training and testing animal recognition models.</li>
</ul>

<h2>Classification Scheme</h2>
<p>The images are classified into the following categories:</p>
<ul>
    <li><strong>Female</strong></li>
    <li><strong>Male</strong></li>
    <li><strong>Primate</strong></li>
    <li><strong>Rodent</strong></li>
    <li><strong>Food</strong></li>
</ul>

<h2>How the Classifier Works</h2>
<ol>
    <li><strong>Data Preparation:</strong> Images from the datasets are organized and preprocessed, including resizing and color adjustments, to ensure consistency.</li>
    <li><strong>Feature Extraction:</strong> Relevant features from images are extracted using the selected similarity or distance measures.</li>
    <li><strong>Training the Classifier:</strong> The kNN algorithm is trained using the preprocessed images and their known categories.</li>
    <li><strong>Classifying New Images:</strong> New images are compared to the trained data to predict their category based on the closest matches.</li>
</ol>

<h2>Evaluation Metrics</h2>
<p>To assess the classifier's performance, the following metrics are used:</p>
<ul>
    <li><strong>Confusion Matrix:</strong> A table that visualizes the classifier's performance by showing true vs. predicted classifications.</li>
    <li><strong>Precision:</strong> The ratio of correctly predicted positive observations to the total predicted positives.</li>
    <li><strong>Recall:</strong> The ratio of correctly predicted positive observations to all actual positives.</li>
    <li><strong>F-measure:</strong> The harmonic mean of precision and recall, providing a balance between the two.</li>
    <li><strong>Accuracy:</strong> The overall correctness of the classifier, calculated as the ratio of correctly predicted observations to the total observations.</li>
</ul>

<h2>Why This Project Matters</h2>
<p>This project is significant for several reasons:</p>
<ul>
    <li><strong>Practical Application:</strong> Image classification is fundamental in many real-world applications such as facial recognition, wildlife monitoring, and cultural heritage preservation.</li>
    <li><strong>Skill Development:</strong> Implementing algorithms from scratch enhances understanding of machine learning principles and programming skills.</li>
    <li><strong>Research and Exploration:</strong> Exploring methods to optimize parameters like the number of neighbors (k) contributes to better model performance and understanding of algorithm dynamics.</li>
</ul>

<h2>Getting Started</h2>
<ol>
    <li><strong>Set Up the Environment:</strong> Ensure you have Python and the necessary libraries installed (e.g., NumPy, OpenCV).</li>
    <li><strong>Prepare the Data:</strong> Download the datasets and organize them according to the classification scheme.</li>
    <li><strong>Run the Classifier:</strong> Use the provided Python scripts to train and test the classifier. Adjust parameters like the number of neighbors (k) and the similarity measures as needed.</li>
    <li><strong>Evaluate Performance:</strong> Review the output metrics to understand the classifier's effectiveness. Use the confusion matrix and calculated metrics for a comprehensive assessment.</li>
</ol>

<h2>Conclusion</h2>
<p>This project demonstrates the development of an image classifier using fundamental machine learning techniques. By building and evaluating the classifier step by step, we gain practical experience in image recognition tasks and a deeper understanding of algorithm implementation. The exploration of optimizing parameters and implementing custom similarity measures contributes to enhancing the classifier's performance and reliability.</p>

<hr>
